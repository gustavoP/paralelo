```{r}
library(SparkR)
library(sparklyr)
library(tictoc)
```

```{r}
Sys.setenv(SPARK_HOME = "/home/gustavo/spark/spark-2.3.2-bin-hadoop2.7")
Sys.setenv(SPARK_HOME_VERSION='2.3.2')
#sc = spark_connect(master = "local")
```

```{r}
sparkR.session()
#sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "4g"))
```

```{r}
tic("load")
vra_wu <- read.df("/home/gustavo/Desktop/vra_wu.csv", "csv", header = "true")
aerodromos = read.df("/home/gustavo/Desktop/Glossario_de_Aerodromo.csv","csv", header = "true")
toc()
```

```{r}
tic("query1")
createOrReplaceTempView(vra_wu, "vra_wu")
createOrReplaceTempView(aerodromos, "aerodromos")

q1 = sql("SELECT * 
    FROM vra_wu
    INNER JOIN aerodromos a1 ON vra_wu.origin = a1.Sigla_OACI
    INNER JOIN aerodromos a2 ON vra_wu.destiny = a2.Sigla_OACI
WHERE (year(depart_expect) == 2017 OR year(arrival_expect) ==2017)
AND (departure_delay >15 AND departure_delay <240)
AND status == 'REALIZADO'
AND a1.Pais == 'BRASIL' 
AND a2.Pais =='BRASIL' ")
query1 = collect(q1)
toc()
rm(query1)
```

```{r}
tic("query2")
createOrReplaceTempView(vra_wu, "vra_wu")
createOrReplaceTempView(aerodromos, "aerodromos")
q2 = sql("SELECT 
    origin, 
    COUNT(origin) as CountOrigem 
    FROM vra_wu
    INNER JOIN aerodromos a1 ON vra_wu.origin = a1.Sigla_OACI
    INNER JOIN aerodromos a2 ON vra_wu.destiny = a2.Sigla_OACI
WHERE (year(depart_expect) == 2017 OR year(arrival_expect) ==2017)
AND (departure_delay >15 AND departure_delay <240)
AND status == 'REALIZADO'
AND a1.Pais == 'BRASIL' 
AND a2.Pais =='BRASIL'
GROUP BY vra_wu.origin")
query2 = collect(q2)
toc()
```
